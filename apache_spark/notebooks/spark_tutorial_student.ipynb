{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from faker import Faker\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.window import Window\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPARK_APP_NAME = os.getenv('SPARK_APP_NAME', 'spark-comprehensive-tutorial')\n",
    "BASE_DIR = Path('/workspace/notebooks')\n",
    "OUTPUT_DIR = BASE_DIR / 'tutorial_output' / 'spark_only'\n",
    "RAW_DIR = OUTPUT_DIR / 'raw'\n",
    "CURATED_DIR = OUTPUT_DIR / 'curated'\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(SPARK_APP_NAME)\n",
    "    .master(os.getenv('SPARK_MASTER', 'local[*]'))\n",
    "    .config('spark.sql.shuffle.partitions', '8')\n",
    "    .config('spark.sql.session.timeZone', 'UTC')\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "spark.sparkContext.setLogLevel('WARN')\n",
    "print('Spark Version:', spark.version)\n",
    "print('Output Dir:', OUTPUT_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Rohdaten erzeugen (Customers, Products, Orders, Order Items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake = Faker('en_US')\n",
    "Faker.seed(42)\n",
    "\n",
    "countries = ['DE', 'US', 'IN', 'JP', 'SE']\n",
    "segments = ['SMB', 'Enterprise', 'Consumer']\n",
    "categories = ['Hardware', 'Software', 'Accessories']\n",
    "\n",
    "customers = [\n",
    "    {'customer_id': i, 'country': countries[i % len(countries)], 'segment': segments[i % len(segments)]}\n",
    "    for i in range(1, 201)\n",
    "]\n",
    "\n",
    "products = [\n",
    "    {\n",
    "        'product_id': i,\n",
    "        'product_name': f'product_{i:03d}',\n",
    "        'category': categories[i % len(categories)],\n",
    "        'unit_price': float((i % 30 + 1) * 3.5),\n",
    "    }\n",
    "    for i in range(1, 101)\n",
    "]\n",
    "\n",
    "orders = []\n",
    "for i in range(1, 1201):\n",
    "    day = (i % 28) + 1\n",
    "    orders.append({\n",
    "        'order_id': i,\n",
    "        'customer_id': (i % 200) + 1,\n",
    "        'status': 'PAID' if i % 5 != 0 else 'CANCELLED',\n",
    "        'order_ts': f'2026-01-{day:02d} {(i % 24):02d}:{(i % 60):02d}:00',\n",
    "    })\n",
    "\n",
    "items = []\n",
    "for order_id in range(1, 1201):\n",
    "    line_count = (order_id % 4) + 1\n",
    "    for line in range(1, line_count + 1):\n",
    "        product_id = ((order_id * line) % 100) + 1\n",
    "        quantity = (line % 5) + 1\n",
    "        items.append({\n",
    "            'order_id': order_id,\n",
    "            'line_id': line,\n",
    "            'product_id': product_id,\n",
    "            'quantity': quantity,\n",
    "        })\n",
    "\n",
    "customers_df = spark.createDataFrame(customers)\n",
    "products_df = spark.createDataFrame(products)\n",
    "orders_df = spark.createDataFrame(orders).withColumn('order_ts', F.to_timestamp('order_ts'))\n",
    "items_df = spark.createDataFrame(items)\n",
    "\n",
    "customers_df.show(5, truncate=False)\n",
    "orders_df.show(5, truncate=False)\n",
    "items_df.show(5, truncate=False)\n",
    "products_df.show(5, truncate=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
