{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea71be2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from faker import Faker\n",
    "import pyspark.sql.functions as F # Spark-SQL col, sum, round, window usw. \n",
    "from pyspark.sql import SparkSession # Einstiegsunkt für DataFrames usw. \n",
    "from pyspark.sql.window import Window\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540063a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "SPARK_APP_NAME = os.getenv('SPARK_APP_NAME', 'spark-comprehensive-tutorial')\n",
    "BASE_DIR = Path('/workspace/notebooks')\n",
    "OUTPUT_DIR = BASE_DIR / 'tutorial_output' / 'spark_only'\n",
    "RAW_DIR = OUTPUT_DIR / 'raw'\n",
    "CURATED_DIR = OUTPUT_DIR / 'curated'\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(SPARK_APP_NAME)\n",
    "    .master(os.getenv('SPARK_MASTER', 'local[*]'))\n",
    "    .config('spark.sql.shuffle.partitions', '8')\n",
    "    .config('spark.sql.session.timeZone', 'UTC')\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "spark.sparkContext.setLogLevel('WARN')\n",
    "print('Spark Version:', spark.version)\n",
    "print('Output Dir:', OUTPUT_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b927216",
   "metadata": {},
   "source": [
    "## 1) Rohdaten erzeugen (Customers, Products, Orders, Order Items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef1747d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake = Faker('en_US')\n",
    "Faker.seed(42)\n",
    "\n",
    "countries = ['DE', 'US', 'IN', 'JP', 'SE']\n",
    "segments = ['SMB', 'Enterprise', 'Consumer']\n",
    "categories = ['Hardware', 'Software', 'Accessories']\n",
    "\n",
    "customers = [\n",
    "    {'customer_id': i, 'country': countries[i % len(countries)], 'segment': segments[i % len(segments)]}\n",
    "    for i in range(1, 201)\n",
    "]\n",
    "\n",
    "products = [\n",
    "    {\n",
    "        'product_id': i,\n",
    "        'product_name': f'product_{i:03d}',\n",
    "        'category': categories[i % len(categories)],\n",
    "        'unit_price': float((i % 30 + 1) * 3.5),\n",
    "    }\n",
    "    for i in range(1, 101)\n",
    "]\n",
    "\n",
    "orders = []\n",
    "for i in range(1, 1201):\n",
    "    day = (i % 28) + 1\n",
    "    orders.append({\n",
    "        'order_id': i,\n",
    "        'customer_id': (i % 200) + 1,\n",
    "        'status': 'PAID' if i % 5 != 0 else 'CANCELLED',\n",
    "        'order_ts': f'2026-01-{day:02d} {(i % 24):02d}:{(i % 60):02d}:00',\n",
    "    })\n",
    "\n",
    "items = []\n",
    "for order_id in range(1, 1201):\n",
    "    line_count = (order_id % 4) + 1\n",
    "    for line in range(1, line_count + 1):\n",
    "        product_id = ((order_id * line) % 100) + 1\n",
    "        quantity = (line % 5) + 1\n",
    "        items.append({\n",
    "            'order_id': order_id,\n",
    "            'line_id': line,\n",
    "            'product_id': product_id,\n",
    "            'quantity': quantity,\n",
    "        })\n",
    "\n",
    "customers_df = spark.createDataFrame(customers)\n",
    "products_df = spark.createDataFrame(products)\n",
    "orders_df = spark.createDataFrame(orders).withColumn('order_ts', F.to_timestamp('order_ts'))\n",
    "items_df = spark.createDataFrame(items)\n",
    "\n",
    "customers_df.show(5, truncate=False)\n",
    "orders_df.show(5, truncate=False)\n",
    "items_df.show(5, truncate=False)\n",
    "products_df.show(5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e753f838-1b67-4d0f-9bef-c4def27bce72",
   "metadata": {},
   "outputs": [],
   "source": [
    "order_lines_df = (\n",
    "    items_df\n",
    "    .join(products_df, on=\"product_id\", how=\"inner\")\n",
    "    .withColumn(\"line_value\", F.col(\"quantity\")*F.col(\"unit_price\"))\n",
    ")\n",
    "\n",
    "order_lines_df.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bbbef1-53ee-428d-a6d6-4e752805b4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "order_summary_df = (\n",
    "    orders_df\n",
    "    .join(customers_df, on=\"customer_id\", how = \"inner\")\n",
    "    .join(order_lines_df, on=\"order_id\", how = \"inner\")\n",
    "    .withColumn(\"order_date\", F.to_date(\"order_ts\"))\n",
    "    .groupBy(\"order_id\", \"order_ts\", \"order_date\", \"status\", \"customer_id\", \"country\", \"segment\")\n",
    "    .agg(\n",
    "        F.count(\"*\").alias(\"line_count\"),\n",
    "        F.sum(\"quantity\").alias(\"item_count\"),\n",
    "        F.round(F.sum(\"line_value\"),2).alias(\"order_value\"),\n",
    "    )\n",
    ")\n",
    "order_summary_df.show(10, truncate=False)\n",
    "order_summary_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1b3753-f47d-4245-8657-8319b5c9bdcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_DIR.mkdir(parents=True, exist_ok=True)\n",
    "CURATED_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "orders_df.write.mode(\"overwrite\").parquet(str(RAW_DIR / 'orders_parquet'))\n",
    "items_df.write.mode('overwrite').parquet(str(RAW_DIR / 'items_parquet'))\n",
    "products_df.write.mode('overwrite').json(str(RAW_DIR / 'products_json')) # demonstration\n",
    "customers_df.write.mode('overwrite').parquet(str(RAW_DIR / 'customers_parquet'))\n",
    "\n",
    "(\n",
    "    order_summary_df\n",
    "    .filter(F.col(\"status\") == \"PAID\")\n",
    "    .write\n",
    "    .mode(\"overwrite\")\n",
    "    .partitionBy(\"order_date\", \"country\")\n",
    "    .parquet(str(CURATED_DIR / \"paid_orders_partitioned\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530ca4af-dcc6-4cb5-a285-91430655d589",
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_df.coalesce(1).rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a861632-cf6f-429b-9c7c-a5d9e91de6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    (1,'one'),\n",
    "    (2,'two'),\n",
    "    (3,'three'),\n",
    "    (4,'four'),\n",
    "    (5,'five'),\n",
    "    (6,'six'),\n",
    "    (7, 'seven'),\n",
    "    (8, 'eight'),\n",
    "    (9, 'nine'),\n",
    "]\n",
    "\n",
    "df = spark.createDataFrame(data, ['id', 'number'])\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b848ac9a-a9af-47b5-a0e4-af28253ea781",
   "metadata": {},
   "outputs": [],
   "source": [
    "mix = df.repartition(8)\n",
    "mix.rdd.glom().collect() # Inhalt jeder Partition ansehen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c965ad7b-a746-4579-8f98-1be14ab95db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mix.repartition(3).rdd.glom().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1161a7-a27b-423b-a682-e006c2d43fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "mix.coalesce(3).rdd.glom().collect() # möglichst wenig Shuffles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ec697e7f-ea2b-4be9-9225-0435f921b942",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# so bitte nicht\n",
    "\n",
    "d = spark.read.csv(\"data/customs_data.csv\", header = True, sep = \";\")\n",
    "#d.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8c3f02d4-ead9-4809-9139-c572592480b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+----------+------+------+--------+------+--------+-------------+-----------+-----------------------------+\n",
      "|month  |country|code      |value |netto |quantity|region|district|direction_eng|measure_eng|load_date                    |\n",
      "+-------+-------+----------+------+------+--------+------+--------+-------------+-----------+-----------------------------+\n",
      "|01/2016|IT     |6204695000|131   |1     |7       |46000 |01      |IM           |ShT        |2024-07-01T00:00:00.000+03:00|\n",
      "|01/2016|CN     |9001900009|112750|18    |0       |46000 |01      |IM           |1          |2024-01-01T00:00:00.000+03:00|\n",
      "|01/2016|BY     |8414302004|392   |57    |8       |50000 |06      |IM           |ShT        |2024-06-01T00:00:00.000+03:00|\n",
      "|01/2016|US     |9018509000|54349 |179   |0       |40000 |02      |IM           |1          |2024-04-01T00:00:00.000+03:00|\n",
      "|01/2016|EE     |9021101000|17304 |372   |0       |46000 |01      |IM           |1          |2024-02-01T00:00:00.000+03:00|\n",
      "|01/2016|FR     |3816000000|323488|253600|0       |40000 |02      |IM           |1          |2024-02-01T00:00:00.000+03:00|\n",
      "|01/2016|MX     |8523519300|1611  |0     |4       |40000 |02      |IM           |ShT        |2024-04-01T00:00:00.000+03:00|\n",
      "|01/2016|JP     |6204520000|29    |1     |2       |46000 |01      |IM           |ShT        |2024-02-01T00:00:00.000+03:00|\n",
      "|01/2016|KR     |6110209100|815   |2     |5       |46000 |01      |IM           |ShT        |2024-01-01T00:00:00.000+03:00|\n",
      "|01/2016|KG     |8527139900|11868 |2127  |2630    |46000 |01      |IM           |ShT        |2024-06-01T00:00:00.000+03:00|\n",
      "|01/2016|ZA     |8421230000|12686 |1785  |3451    |45000 |01      |IM           |ShT        |2024-03-01T00:00:00.000+03:00|\n",
      "|01/2016|CN     |8518109500|12    |0     |10      |65000 |05      |IM           |ShT        |2024-03-01T00:00:00.000+03:00|\n",
      "|01/2016|TR     |8417900000|206453|17297 |1       |92000 |04      |IM           |ShT        |2024-06-01T00:00:00.000+03:00|\n",
      "|01/2016|IT     |3906100000|4492  |1075  |0       |45000 |01      |IM           |1          |2024-02-01T00:00:00.000+03:00|\n",
      "|01/2016|CZ     |8708409909|41    |2     |0       |46000 |01      |IM           |1          |2024-01-01T00:00:00.000+03:00|\n",
      "|01/2016|ES     |6404191000|11822 |346   |760     |45000 |01      |IM           |PAR        |2024-01-01T00:00:00.000+03:00|\n",
      "|01/2016|IT     |9404909000|6801  |485   |0       |46000 |01      |IM           |1          |2024-03-01T00:00:00.000+03:00|\n",
      "|01/2016|UA     |8207801900|35793 |1020  |0       |14000 |01      |IM           |1          |2024-02-01T00:00:00.000+03:00|\n",
      "|01/2016|CN     |3304100000|59678 |10829 |0       |46000 |01      |IM           |1          |2024-06-01T00:00:00.000+03:00|\n",
      "|01/2016|SI     |6104440000|1470  |13    |15      |45000 |01      |IM           |ShT        |2024-05-01T00:00:00.000+03:00|\n",
      "+-------+-------+----------+------+------+--------+------+--------+-------------+-----------+-----------------------------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "d.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "87a524c3-d82a-4767-bf77-378ed97d8037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0--------------------------------------\n",
      " month         | 01/2016                       \n",
      " country       | IT                            \n",
      " code          | 6204695000                    \n",
      " value         | 131                           \n",
      " netto         | 1                             \n",
      " quantity      | 7                             \n",
      " region        | 46000                         \n",
      " district      | 01                            \n",
      " direction_eng | IM                            \n",
      " measure_eng   | ShT                           \n",
      " load_date     | 2024-07-01T00:00:00.000+03:00 \n",
      "-RECORD 1--------------------------------------\n",
      " month         | 01/2016                       \n",
      " country       | CN                            \n",
      " code          | 9001900009                    \n",
      " value         | 112750                        \n",
      " netto         | 18                            \n",
      " quantity      | 0                             \n",
      " region        | 46000                         \n",
      " district      | 01                            \n",
      " direction_eng | IM                            \n",
      " measure_eng   | 1                             \n",
      " load_date     | 2024-01-01T00:00:00.000+03:00 \n",
      "only showing top 2 rows\n"
     ]
    }
   ],
   "source": [
    "d.show(2, False, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0dffa30a-e8fd-45c7-b0ce-225254525c26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 68:====================================================>   (15 + 1) / 16]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|country|\n",
      "+-------+\n",
      "|EE     |\n",
      "|FR     |\n",
      "|LT     |\n",
      "|MY     |\n",
      "|IL     |\n",
      "|AT     |\n",
      "|EU     |\n",
      "|BA     |\n",
      "|PK     |\n",
      "|MM     |\n",
      "|JO     |\n",
      "|AU     |\n",
      "|NZ     |\n",
      "|SA     |\n",
      "|HT     |\n",
      "|DZ     |\n",
      "|BB     |\n",
      "|AD     |\n",
      "|LS     |\n",
      "|SL     |\n",
      "+-------+\n",
      "only showing top 20 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "d.select(\"country\").distinct().show(truncate=False) # 2*1024 / 128 = 16 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c391f83-71c4-4f54-8a40-00578730281a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_de = (\n",
    "    d\n",
    "    .where(F.col('country') == 'DE')\n",
    "    .where(F.col('value').isNotNull())\n",
    ") # DataFrame-API\n",
    "\n",
    "# SQL-String\n",
    "\n",
    "df_de2 = (\n",
    "    d\n",
    "    .where(''' country == \"DE\" ''')\n",
    "    .where(''' value IS NOT NULL ''')\n",
    ")\n",
    "\n",
    "print(df_de.count() == df_de2.count())\n",
    "df_de.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9ad1051f-3d23-4fb1-a1a1-072d59d54188",
   "metadata": {},
   "outputs": [],
   "source": [
    "final = (\n",
    "    df_de\n",
    "    .select(\n",
    "        'month',\n",
    "        'country',\n",
    "        'code',\n",
    "        'value',\n",
    "        'netto',\n",
    "        'quantity',\n",
    "        'region',\n",
    "        'district',\n",
    "        'direction_eng',\n",
    "        'measure_eng',\n",
    "        F.col('load_date').cast('date'), # Typumwandlung\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a414aca3-ebd5-466c-a692-d4e0d3c58979",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 84:=============================================>          (13 + 3) / 16]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl Partitionen 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "(\n",
    "    final\n",
    "    .write\n",
    "    .format('csv')\n",
    "    .options(header='True', sep=';')\n",
    "    .csv('data/final_no_control')\n",
    ")\n",
    "\n",
    "partition_num = final.rdd.getNumPartitions()\n",
    "print(f'Anzahl Partitionen {partition_num}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fc53601d-5cab-4298-b5e0-48a34d37ed1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl Partitionen 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load_date distinct: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 96:====================================================>   (15 + 1) / 16]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl Partitionen 1\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    final\n",
    "    .coalesce(1)\n",
    "    .write\n",
    "    .format('csv')\n",
    "    .options(header='True', sep=';')\n",
    "    .csv('data/final_one_file')\n",
    ")\n",
    "\n",
    "partition_num = final.coalesce(1).rdd.getNumPartitions()\n",
    "print(f'Anzahl Partitionen {partition_num}')\n",
    "\n",
    "\n",
    "(\n",
    "    final\n",
    "    .write\n",
    "    .partitionBy('load_date')\n",
    "    .format('csv')\n",
    "    .options(header='True', sep=';')\n",
    "    .csv('data/final_partitioned')\n",
    ")\n",
    "\n",
    "print_df = final.select('load_date').distinct()\n",
    "print(f'Load_date distinct: {print_df.count()}')\n",
    "\n",
    "\n",
    "(\n",
    "    final\n",
    "    .repartition(1, 'load_date')\n",
    "    .write\n",
    "    .partitionBy('load_date')\n",
    "    .format('csv')\n",
    "    .options(header='True', sep=';')\n",
    "    .csv('data/final_partitioned_repart')\n",
    ")\n",
    "\n",
    "partition_num = final.repartition(1, 'load_date').rdd.getNumPartitions()\n",
    "print(f'Anzahl Partitionen {partition_num}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b7b4e6be-d07f-42c6-8ecc-937a82be8ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "350998"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reader_no_control = (\n",
    "    spark\n",
    "    .read\n",
    "    .csv('data/final_no_control/', header=True, sep=';')\n",
    "    .where(''' load_date = \"2024-01-01\" ''')\n",
    ")\n",
    "\n",
    "reader_final_one_file = (\n",
    "    spark\n",
    "    .read\n",
    "    .csv('data/final_one_file/', header=True, sep=';')\n",
    "    .where(''' load_date = \"2024-01-01\" ''')\n",
    ")\n",
    "\n",
    "reader_partitioned = (\n",
    "    spark\n",
    "    .read\n",
    "    .csv('data/final_partitioned', header=True, sep=';')\n",
    "    .where(''' load_date = \"2024-01-01\" ''')\n",
    ")\n",
    "\n",
    "reader_partitioned_repart = (\n",
    "    spark\n",
    "    .read\n",
    "    .csv('data/final_partitioned_repart', header=True, sep=';')\n",
    "    .where(''' load_date = \"2024-01-01\" ''')\n",
    ")\n",
    "\n",
    "reader_no_control.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "29dd6c0e-0d2c-4270-9ad2-2b8a8d71a827",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = final.toPandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "14795d64-e915-4278-855e-509eb7b29dff",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'rdd'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[32m/tmp/ipykernel_2081/4108395075.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df.rdd\n",
      "\u001b[32m/usr/local/lib/python3.11/site-packages/pandas/core/generic.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   6202\u001b[39m             \u001b[38;5;28;01mand\u001b[39;00m name \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01min\u001b[39;00m self._accessors\n\u001b[32m   6203\u001b[39m             \u001b[38;5;28;01mand\u001b[39;00m self._info_axis._can_hold_identifiers_and_holds_name(name)\n\u001b[32m   6204\u001b[39m         ):\n\u001b[32m   6205\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m self[name]\n\u001b[32m-> \u001b[39m\u001b[32m6206\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m object.__getattribute__(self, name)\n",
      "\u001b[31mAttributeError\u001b[39m: 'DataFrame' object has no attribute 'rdd'"
     ]
    }
   ],
   "source": [
    "df.rdd"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
